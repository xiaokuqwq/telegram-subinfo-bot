import asyncio
import base64
import re
import time
import html
import logging
from datetime import datetime
from io import BytesIO

import aiohttp
import yaml
from telegram import Update, constants
from telegram.ext import ApplicationBuilder, MessageHandler, filters, ContextTypes

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

# --- é™æ€é…ç½® ---
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
PROXY_URL = os.getenv("TELEGRAM_PROXY_URL")
REMOTE_MAPPINGS_URL = "https://raw.githubusercontent.com/Hyy800/Quantumult-X/refs/heads/Nana/ymys.txt"
REMOTE_CONFIG_MAPPINGS = {}

# åœ°åŒºè¯†åˆ«è§„åˆ™ (åŸç‰ˆ)
REGION_RULES = [
    ('é¦™æ¸¯', ['é¦™æ¸¯', 'hong kong', 'hongkong', 'hk', 'hkg']),
    ('å°æ¹¾', ['å°æ¹¾', 'taiwan', 'tw', 'taipei', 'tpe']),
    ('æ—¥æœ¬', ['æ—¥æœ¬', 'japan', 'jp', 'tokyo', 'osaka', 'jap']),
    ('æ–°åŠ å¡', ['æ–°åŠ å¡', 'singapore', 'sg', 'sgp']),
    ('éŸ©å›½', ['éŸ©å›½', 'korea', 'kr', 'seoul', 'kor']),
    ('ç¾å›½', ['ç¾å›½', 'united states', 'us', 'usa', 'los angeles', 'san jose']),
]

# å…¨å±€å˜é‡
GLOBAL_SEMAPHORE = asyncio.Semaphore(50)  # aiohttp æ€§èƒ½æ›´å¥½ï¼Œå¹¶å‘å¯ä»¥å¼€å¤§ä¸€ç‚¹
shared_session = None

# --- å·¥å…·å‡½æ•° ---

def format_size(size: float) -> str:
    units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
    level = 0
    while size >= 1024 and level < len(units) - 1:
        size /= 1024
        level += 1
    return f"{size:.2f} {units[level]}"

def parse_user_info(header: str):
    info = {}
    for part in header.split(';'):
        if '=' in part:
            k, v = part.split('=', 1)
            info[k.strip().lower()] = v.strip()
    return info

def analyze_regions(proxies):
    stats = {}
    for p in proxies:
        name = str(p.get('name', '')).lower()
        found = False
        for region, keywords in REGION_RULES:
            if any(k in name for k in keywords):
                stats[region] = stats.get(region, 0) + 1
                found = True
                break
        if not found:
            stats['å…¶ä»–'] = stats.get('å…¶ä»–', 0) + 1
    
    if not stats: return "æ— æœ‰æ•ˆèŠ‚ç‚¹"
    return " | ".join([f"{k}:{v}" for k, v in stats.items()])

async def fetch_node_info(url: str):
    """ä½¿ç”¨ aiohttp è·å–èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯"""
    try:
        async with shared_session.get(url, timeout=10) as resp:
            data = await resp.text()
            if 'proxies' in data:
                config = yaml.safe_load(data)
                proxies = config.get('proxies', [])
                return {"count": len(proxies), "detail": analyze_regions(proxies)}
            try:
                missing_padding = len(data) % 4
                if missing_padding: data += '=' * (4 - missing_padding)
                decoded = base64.b64decode(data).decode('utf-8')
                lines = [l for l in decoded.splitlines() if '://' in l]
                if lines: return {"count": len(lines), "detail": f"{len(lines)}ä¸ªé€šç”¨èŠ‚ç‚¹"}
            except: pass
    except: pass
    return None

async def process_sub(url: str):
    """aiohttp æ ¸å¿ƒå¤„ç†é€»è¾‘"""
    async with GLOBAL_SEMAPHORE:
        try:
            headers = {'User-Agent': 'Clash-Verge/1.0.0'}
            async with shared_session.get(url, headers=headers, timeout=15) as resp:
                if resp.status != 200:
                    return {"success": False, "url": url, "error": f"HTTP {resp.status}"}
                
                user_info = resp.headers.get('subscription-userinfo')
                if not user_info:
                    return {"success": False, "url": url, "error": "ä¸è¿”å›æµé‡Header"}
                
                info = parse_user_info(user_info)
                u, d, t, e = int(info.get('upload', 0)), int(info.get('download', 0)), int(info.get('total', 0)), int(info.get('expire', 0))
                
                used = u + d
                percent = round((used / t) * 100, 2) if t > 0 else 0
                name = next((v for k, v in REMOTE_CONFIG_MAPPINGS.items() if k in url), "æœªçŸ¥æœºåœº")
                node = await fetch_node_info(url)
                
                return {
                    "success": True, "url": url, "name": name, "total": t, "used": used,
                    "remain": max(0, t - used), "percent": percent, "expire_ts": e,
                    "node": node, "up": u, "down": d
                }
        except Exception as err:
            return {"success": False, "url": url, "error": "è¿æ¥è¶…æ—¶/å¼‚å¸¸"}

# --- æ¶ˆæ¯å¤„ç†å™¨ ---

async def handle_request(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.effective_message
    if not msg: return

    content = msg.text or msg.caption or ""
    urls = re.findall(r'https?://[^\s]+', content)

    if msg.document and (msg.document.file_name.endswith('.txt') or msg.document.mime_type == 'text/plain'):
        file = await msg.document.get_file()
        byte_content = await file.download_as_bytearray()
        urls.extend(re.findall(r'https?://[^\s]+', byte_content.decode('utf-8', errors='ignore')))

    urls = list(dict.fromkeys(urls))
    if not urls: return

    status_msg = await msg.reply_text("ğŸš€ aiohttp æé€Ÿå¼•æ“å¤„ç†ä¸­...")

    tasks = [process_sub(url) for url in urls]
    responses = await asyncio.gather(*tasks)

    results = []
    for res in responses:
        safe_url = html.escape(res['url'])
        if not res["success"]:
            results.append(f"âŒ <b>è§£æå¤±è´¥</b>\nè®¢é˜…: <code>{safe_url}</code>\nåŸå› : {res['error']}")
            continue
        
        filled = min(15, int(res['percent'] / 6.6))
        bar = "â–ˆ" * filled + "â–‘" * (15 - filled)
        expire_date = datetime.fromtimestamp(res['expire_ts']).strftime('%Y-%m-%d') if res['expire_ts'] > 0 else "æ°¸ä¹…/æœªçŸ¥"
        
        output = (
            f"ğŸ“„ <b>æœºåœºåç§°</b>: <code>{html.escape(res['name'])}</code>\n"
            f"ğŸ·ï¸ <b>è®¢é˜…é“¾æ¥</b>: <code>{safe_url}</code>\n"
            f"ğŸ“Š <b>æµé‡ä¿¡æ¯</b>:\n"
            f"é¢„è§ˆ: <code>[{bar}] {res['percent']}%</code>\n"
            f"æ€»æµé‡: <code>{format_size(res['total'])}</code>\n"
            f"å·²ä½¿ç”¨: <code>{format_size(res['used'])}</code> (â†‘{format_size(res['up'])} â†“{format_size(res['down'])})\n"
            f"å‰©ä½™é‡: <code>{format_size(res['remain'])}</code>\n"
            f"â° <b>åˆ°æœŸæ—¶é—´</b>: <code>{expire_date}</code>\n"
        )
        if res['node']:
            output += f"ğŸŒ <b>èŠ‚ç‚¹ä¿¡æ¯</b>: <code>{res['node']['count']}ä¸ªèŠ‚ç‚¹ ({res['node']['detail']})</code>"
        
        results.append(output)

    final_text = "\n" + ("="*20) + "\n\n".join(results)

    if len(final_text) > 4000:
        clean_text = re.sub('<[^<]+?>', '', final_text)
        bio = BytesIO(clean_text.encode())
        bio.name = "aio_report.txt"
        await msg.reply_document(document=bio, caption="âœ… æ‰¹é‡æŸ¥è¯¢å®Œæˆ")
        await status_msg.delete()
    else:
        await status_msg.edit_text(final_text, parse_mode=constants.ParseMode.HTML, disable_web_page_preview=True)

# --- å…¥å£ ---

async def main():
    global shared_session
    # åˆå§‹åŒ– aiohttp è¿æ¥æ± 
    connector = aiohttp.TCPConnector(limit=100, ttl_dns_cache=300)
    shared_session = aiohttp.ClientSession(connector=connector)

    # åŠ è½½æ˜ å°„
    try:
        async with shared_session.get(REMOTE_MAPPINGS_URL) as r:
            text = await r.text()
            for line in text.splitlines():
                if '=' in line and not line.startswith('#'):
                    k, v = line.split('=', 1)
                    REMOTE_CONFIG_MAPPINGS[k.strip()] = v.strip()
    except: pass

    app = ApplicationBuilder().token(TOKEN).concurrent_updates(True).build()
    app.add_handler(MessageHandler(filters.TEXT | filters.Document.Category("text/plain"), handle_request))
    
    print(">>> aiohttp æé€Ÿå¹¶å‘ç‰ˆå¯åŠ¨...")
    
    async with app:
        await app.initialize()
        await app.start()
        await app.updater.start_polling()
        await asyncio.Event().wait()
    
    await shared_session.close()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
